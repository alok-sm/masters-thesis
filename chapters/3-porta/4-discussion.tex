\section{Conclusion}

This paper addresses the challenges of providing effective feedback on
the contents of software tutorials. To do so, we created Porta, a system
that automatically builds \emph{tutorial profiles} by tracking user activity within a tutorial webpage and across multiple applications.
Porta surfaces these profiles as interactive visualizations that show
hotspots of user focus alongside details of logged application events
and embedded segments of recorded screencast videos. We found via a user
study of 3 tutorial creators and 12 learners that Porta helped both sets
of users reflect more concretely about what parts of the tutorials
caused the most trouble and what could potentially be improved. Porta
opens up possibilities for systematic user testing of technical
documentation by providing fine-grained data to both test participants
and tutorial creators.

%\todo{we need a good story to address why not just do user testing in
%person and take good notes or videos, the old fashioned way. [Kandarp:
%old fashioned way is less objective, and harder and more time-consuming
%to review] how is
%porta better than doing this?!? how does this SCALE IT UP?!? don't
%overclaim, though.}
